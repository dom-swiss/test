{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n\n# Practice lab\n\n</center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n# **Scenario: Text Analysis**\n\n</center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **45** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# What is text analysis?\nText analysis, also known as text mining or text analytics, refers to the process of extracting meaningful information and insights from textual data.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n \nAfter completing this lab, you will be able to:\n- Use Python commands to perform text analysis.\n- Convert the text to lowercase and then find and count the frequency of all unique words, as well as a specified word.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, you will be using the following data types:\n* List\n* Strings\n* Classes and objects\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Let's consider a real-life scenario where you are analyzing customer feedback for a product. You have a large data set of customer reviews in the form of strings, and you want to extract useful information from them using the three identified tasks:**\n\n**Task 1. String in lowercase:**\nYou want to pre-process the customer feedback by converting all the text to lowercase. This step helps standardize the text. Lower casing the text allows you to focus on the content rather than the specific letter casing.\n\n**Task 2. Frequency of all words in a given string:**\nAfter converting the text to lowercase, you want to determine the frequency of each word in the customer feedback. This information will help you identify which words are used more frequently, indicating the key aspects or topics that customers are mentioning in their reviews. By analyzing the word frequencies, you can gain insights into the most common issues raised by customers.\n\n**Task 3. Frequency of a specific word:**\nIn addition to analyzing the overall word frequencies, you want to specifically track the frequency of a particular word that is relevant to your analysis. For example, you might be interested in monitoring how often the word \"reliable\" appears in customer reviews to gauge customer sentiment about the product's reliability. By focusing on the frequency of a specific word, you can gain a deeper understanding of customer opinions or preferences related to that particular aspect.\n\nBy performing these tasks on the customer feedback dataset, you can gain valuable insights into customer sentiment\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n# Part-A\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n**Note: In Part-A, you would not be getting any output as you are just storing the string and creating a class.**\n    </center>\n    \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Define a string\n\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\" <br>\n**Hint: Use a variable and store the above string.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Press Shift+Enter to run the code\ngivenstring=\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### To achieve the tasks mentioned in the scenario, you need to create a class with three different methods.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Define the class and its attributes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Create a class named TextAnalyzer.\n2. Define the constructor `__init__` method that takes a text argument.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Please do not run this code cell as it is incomplete and will produce an error.\n\n# Let's create a class called TextAnalyzer to analyze text.\nclass TextAnalyzer(object):\n    # The __init__ method initializes the class with a 'text' parameter.\n    # You will store the provided 'text' as an instance variable.\n    def __init__(self, text):",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Implement a code to format the text in lowercase\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Inside the constructor, convert the text argument to lowercase using the `lower()` method.\n2. Then, remove punctuation marks (periods, exclamation marks, commas, and question marks) from the text using the `replace()` method.\n3. Finally, assign the formatted text to a new attribute called fmtText.\n\n**Here you will be updating the above `TextAnalyzer` class with the points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Press Shift+Enter to run the code.\nclass TextAnalzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n\n        self.fmtText = formattedText",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for Solution</summary>\n\n```python\nclass TextAnalzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Implement a code to count the frequency of all unique words\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "* In this step, you will implement the `freqAll()` method with the below parameters:\n     1. Split the fmtText attribute into individual words using the `split()` method.\n     2. Create an empty dictionary to store the word frequency.\n     3. Iterate over the list of words and update the frequency dictionary accordingly.\n     4. Use `count` method for counting the occurence.\n     5. Return the frequency dictionary.\n     \n**Update the above `TextAnalyzer` class with points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Press shift+Enter to run the code\nclass TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n\n        self.fmtText = formattedText\n\n    \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(\" \")\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n\n        return freqMap\n\n    def freqOf(self,word):\n        # get frequency map\n        freqDict = self.freqAll()\n        \n        if word in freqDict:\n            return freqDict[word]\n        else:\n            return 0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Click here for solution</summary>\n\n```python\nclass TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText\n        \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(' ')\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n        \n        return freqMap\n```\n    \n</details>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 5: Implement a code to count the frequency of a specific word\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In step-5, you have to implement the `freqOf(word)` method that takes a word argument:\n   1. Create a method and pass the word that needs to be found.\n   2. Get the `freqAll` method to look for count and check if that word is in the list.\n   3. Return the count. If the word is not found, the count returned is 0.\n   \n**Update the above `TextAnalyzer` class with the points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Press Shift+Enter to run the code\nclass TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n\n        self.fmtText = formattedText\n\n    \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(\" \")\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n\n        return freqMap\n\n    def freqOf(self,word):\n        # get frequency map\n        freqDict = self.freqAll()\n        \n        if word in freqDict:\n            return freqDict[word]\n        else:\n            return 0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for solution</summary>\n\n```python\nclass TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText\n        \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(' ')\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n        \n        return freqMap\n    \n    def freqOf(self,word):\n        # get frequency map\n        freqDict = self.freqAll()\n        \n        if word in freqDict:\n            return freqDict[word]\n        else:\n            return 0\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Now, you have successfully created a class with three methods.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n# Part-B \n  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n**In Part B, you will call the functions created in Part A, allowing the functions to execute and generate output.**\n    </center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Create an instance of TextAnalyzer class\n* Instantiate the TextAnalyzer class by passing the given string as an argument.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# type your code here\nanalyzed = TextAnalyzer(givenstring)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for solution</summary>\n\n```python\nanalyzed = TextAnalyzer(givenstring)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Call the function that converts the data into lowercase\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Press Shift+Enter to run the code.\nprint(\"Formatted Text:\", analyzed.fmtText)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Formatted Text: lorem ipsum dolor diam amet consetetur lorem magna sed diam nonumy eirmod tempor diam et labore et diam magna et diam amet\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for solution</summary>\n\n```python\nprint(\"Formatted Text:\", analyzed.fmtText)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You have successfully converted string into lowercase.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Call the function that counts the frequency of all unique words from the data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Press Shift+Enter to run the code.\nfreqMap = analyzed.freqAll()\nprint(freqMap)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'diam': 5, 'lorem': 2, 'amet': 2, 'magna': 2, 'tempor': 1, 'et': 3, 'dolor': 1, 'nonumy': 1, 'sed': 1, 'consetetur': 1, 'labore': 1, 'eirmod': 1, 'ipsum': 1}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for solution</summary>\n\n```python\nfreqMap = analyzed.freqAll()\nprint(freqMap)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You have successfully calculated the frequency of all unique words in the string.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Call the function that counts the frequency of a specific word\nHere, you will call the function that counts the frequency of the word \"lorem\".\n<br>\n\nPrint the output.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# type your code here\nprint(analyzed.freqOf(\"lorem\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for solution</summary>\n\n```python\nword = \"lorem\"\nfrequency = analyzed.freqOf(word)\nprint(\"The word\",word,\"appears\",frequency,\"times.\")\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You have successfully calculated the frequency of all specified words.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Dominik's own solution asking Gemini:\n# “create python scripts for typical text analyzer functionality using object with various methods.”\n# Gemini: \n\nclass TextAnalyzer:\n    \"\"\"\n    A class for analyzing text and providing various statistics.\n    \"\"\"\n\n    def __init__(self, text=\"\"):\n        \"\"\"\n        Initializes the TextAnalyzer object with the given text.\n\n        Args:\n            text (str, optional): The text to analyze. Defaults to an empty string.\n        \"\"\"\n        self.text = text.lower()  # Store text in lowercase for case-insensitive analysis\n        self.word_counts = {}\n        self.char_counts = {}\n        self._analyze_text()\n\n    def _analyze_text(self):\n        \"\"\"\n        Internal method to perform initial analysis of the text.\n        Counts words and characters.\n        \"\"\"\n        words = self.text.split()\n        for word in words:\n            # Remove punctuation from words for more accurate counting\n            cleaned_word = ''.join(char for char in word if char.isalnum())\n            if cleaned_word:\n                self.word_counts[cleaned_word] = self.word_counts.get(cleaned_word, 0) + 1\n\n        for char in self.text:\n            if char.isalnum():  # Count only alphanumeric characters\n                self.char_counts[char] = self.char_counts.get(char, 0) + 1\n\n    def set_text(self, new_text):\n        \"\"\"\n        Sets a new text for analysis and re-analyzes it.\n\n        Args:\n            new_text (str): The new text to analyze.\n        \"\"\"\n        self.text = new_text.lower()\n        self.word_counts = {}\n        self.char_counts = {}\n        self._analyze_text()\n\n    def get_word_count(self):\n        \"\"\"\n        Returns the total number of words in the text.\n\n        Returns:\n            int: The total word count.\n        \"\"\"\n        return len(self.text.split())\n\n    def get_unique_word_count(self):\n        \"\"\"\n        Returns the number of unique words in the text.\n\n        Returns:\n            int: The number of unique words.\n        \"\"\"\n        return len(self.word_counts)\n\n    def get_word_frequency(self, word):\n        \"\"\"\n        Returns the frequency of a specific word in the text.\n\n        Args:\n            word (str): The word to find the frequency of (case-insensitive).\n\n        Returns:\n            int: The frequency of the word, or 0 if the word is not found.\n        \"\"\"\n        cleaned_word = ''.join(char for char in word.lower() if char.isalnum())\n        return self.word_counts.get(cleaned_word, 0)\n\n    def get_top_n_words(self, n=5):\n        \"\"\"\n        Returns the top N most frequent words and their counts.\n\n        Args:\n            n (int, optional): The number of top words to return. Defaults to 5.\n\n        Returns:\n            list: A list of tuples, where each tuple contains (word, frequency),\n                  sorted in descending order of frequency.\n        \"\"\"\n        sorted_words = sorted(self.word_counts.items(), key=lambda item: item[1], reverse=True)\n        return sorted_words[:n]\n\n    def get_character_count(self):\n        \"\"\"\n        Returns the total number of alphanumeric characters in the text.\n\n        Returns:\n            int: The total alphanumeric character count.\n        \"\"\"\n        return len(self.char_counts)\n\n    def get_character_frequency(self, char):\n        \"\"\"\n        Returns the frequency of a specific character in the text.\n\n        Args:\n            char (str): The character to find the frequency of (case-insensitive).\n\n        Returns:\n            int: The frequency of the character, or 0 if the character is not found.\n        \"\"\"\n        return self.char_counts.get(char.lower(), 0)\n\n    def get_top_n_characters(self, n=5):\n        \"\"\"\n        Returns the top N most frequent characters and their counts.\n\n        Args:\n            n (int, optional): The number of top characters to return. Defaults to 5.\n\n        Returns:\n            list: A list of tuples, where each tuple contains (character, frequency),\n                  sorted in descending order of frequency.\n        \"\"\"\n        sorted_chars = sorted(self.char_counts.items(), key=lambda item: item[1], reverse=True)\n        return sorted_chars[:n]\n\n    def get_average_word_length(self):\n        \"\"\"\n        Calculates and returns the average length of words in the text.\n\n        Returns:\n            float: The average word length, or 0 if there are no words.\n        \"\"\"\n        total_word_length = sum(len(word) for word in self.text.split())\n        total_words = self.get_word_count()\n        if total_words > 0:\n            return total_word_length / total_words\n        else:\n            return 0\n\n    def get_sentence_count(self):\n        \"\"\"\n        Estimates the number of sentences in the text based on common sentence-ending punctuation.\n\n        Returns:\n            int: The estimated number of sentences.\n        \"\"\"\n        return len(re.split(r'[.!?]+', self.text)) - 1\n\nimport re\n\n# Example Usage:\nif __name__ == \"__main__\":\n    text1 = \"This is a sample text. This text has some repeated words like this and text.\"\n    analyzer1 = TextAnalyzer(text1)  \n\n    # print(analyzer1)         #analyzer cannot be printed and leads to error <__main__.TextAnalyzer object at 0x251d3b0>\n    # type(analyzer1)\n    # analyzer1\n    # different functions and attributes have to be used to display content of object \"analyzer1\"\n    print(\"Visualizing analyzer1 using __dict__:\")\n    print(analyzer1.__dict__)\n\n    print(\"\\nVisualizing analyzer1 using vars():\")\n    print(vars(analyzer1))\n    print()\n    print(f\"Original Text: {text1}\")\n    print(f\"Total Word Count: {analyzer1.get_word_count()}\")\n    print(f\"Unique Word Count: {analyzer1.get_unique_word_count()}\")\n    print(f\"Frequency of 'this': {analyzer1.get_word_frequency('this')}\")\n    print(f\"Top 3 words: {analyzer1.get_top_n_words(3)}\")\n    print(f\"Total Character Count (alphanumeric): {analyzer1.get_character_count()}\")\n    print(f\"Frequency of 's': {analyzer1.get_character_frequency('s')}\")\n    print(f\"Top 2 characters: {analyzer1.get_top_n_characters(2)}\")\n    print(f\"Average Word Length: {analyzer1.get_average_word_length():.2f}\") # \":.2f\" restricts only 2 decimals to be printed\n    print(f\"Estimated Sentence Count: {analyzer1.get_sentence_count()}\")\n\n    text2 = \"Another example! With fewer words.\"\n    analyzer1.set_text(text2)\n    print(f\"\\nNew Text: {text2}\")\n    print(f\"Total Word Count: {analyzer1.get_word_count()}\")\n    print(f\"Unique Word Count: {analyzer1.get_unique_word_count()}\")\n    print(f\"Frequency of 'with': {analyzer1.get_word_frequency('with')}\")\n    print(f\"Top 2 words: {analyzer1.get_top_n_words(2)}\")\n    print(f\"Average Word Length: {analyzer1.get_average_word_length():.2f}\")\n    print(f\"Estimated Sentence Count: {analyzer1.get_sentence_count()}\")\n\n    analyzer2 = TextAnalyzer(\"Hello World\")\n    print(f\"\\nText: Hello World\")\n    print(f\"Word counts: {analyzer2.word_counts}\")\n    print(f\"Character counts: {analyzer2.char_counts}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Visualizing analyzer1 using __dict__:\n{'text': 'this is a sample text. this text has some repeated words like this and text.', 'word_counts': {'this': 3, 'is': 1, 'a': 1, 'sample': 1, 'text': 3, 'has': 1, 'some': 1, 'repeated': 1, 'words': 1, 'like': 1, 'and': 1}, 'char_counts': {'t': 10, 'h': 4, 'i': 5, 's': 8, 'a': 5, 'm': 2, 'p': 2, 'l': 2, 'e': 9, 'x': 3, 'o': 2, 'r': 2, 'd': 3, 'w': 1, 'k': 1, 'n': 1}}\n\nVisualizing analyzer1 using vars():\n{'text': 'this is a sample text. this text has some repeated words like this and text.', 'word_counts': {'this': 3, 'is': 1, 'a': 1, 'sample': 1, 'text': 3, 'has': 1, 'some': 1, 'repeated': 1, 'words': 1, 'like': 1, 'and': 1}, 'char_counts': {'t': 10, 'h': 4, 'i': 5, 's': 8, 'a': 5, 'm': 2, 'p': 2, 'l': 2, 'e': 9, 'x': 3, 'o': 2, 'r': 2, 'd': 3, 'w': 1, 'k': 1, 'n': 1}}\n\nOriginal Text: This is a sample text. This text has some repeated words like this and text.\nTotal Word Count: 15\nUnique Word Count: 11\nFrequency of 'this': 3\nTop 3 words: [('this', 3), ('text', 3), ('is', 1)]\nTotal Character Count (alphanumeric): 16\nFrequency of 's': 8\nTop 2 characters: [('t', 10), ('e', 9)]\nAverage Word Length: 4.13\nEstimated Sentence Count: 2\n\nNew Text: Another example! With fewer words.\nTotal Word Count: 5\nUnique Word Count: 5\nFrequency of 'with': 1\nTop 2 words: [('another', 1), ('example', 1)]\nAverage Word Length: 6.00\nEstimated Sentence Count: 2\n\nText: Hello World\nWord counts: {'hello': 1, 'world': 1}\nCharacter counts: {'h': 1, 'e': 1, 'l': 3, 'o': 2, 'w': 1, 'r': 1, 'd': 1}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\n**Akansha yadav**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--\n## Change Log\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--\n|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-11-05|0.4|Abhishek Gagneja| Updated lab instructions|\n|2023-05-17|0.3|Akansha yadav| Created lab under maintenance|\n|2020-07-17|0.1|Sam     |Create Lab Template|\n|2022-11-19|0.2|Shengkai|Update Lab Template|\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "© Copyright IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}